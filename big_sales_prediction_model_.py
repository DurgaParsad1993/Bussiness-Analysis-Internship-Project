# -*- coding: utf-8 -*-
"""Author: Durga Parsad"""
"""Big Sales Prediction Model .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/161uOsSOrTENy0ufKO_5pizIab4GaZnXN

# **Big Sales Prediction Model**

## **Objective**

Create a Predictive Model and predict particular Item Outlet Sales.

## **Data Source**

www.github.com /YBI Foundation /Big Sales Data

## **Import Library**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""## **Import Data**"""

df = pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/Big%20Sales%20Data.csv', delimiter=',')

"""## **Describe Data**"""

df.head()

df.info()

df.describe()

df.shape

df.columns

"""## **Data Visualization**"""

import seaborn as sns
sns.pairplot(df)

"""## **Data Preprocessing**

####**Handling Missing Values**
"""

df.isnull().sum()

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform("mean"),inplace = True)

df.isnull().sum()

"""####**Handling Categorial Columns Variables**

**Item_Identifier**
"""

df['Item_Identifier'].value_counts()

"""**Item_Fat_Content**"""

df['Item_Fat_Content'].value_counts()

df.replace({'Item_Fat_Content':{'LF':'Low Fat', 'reg':'Regular','low fat':'Low Fat'}},inplace =True)

df['Item_Fat_Content'].value_counts()

df.replace({'Item_Fat_Content':{'Low Fat':0,'Regular':1}},inplace =True)

df['Item_Fat_Content'].value_counts()

"""**Item_Type**"""

df['Item_Type'].value_counts()

df.replace({'Item_Type':{'Fruits and Vegetables':0,'Snack Foods':0, 'Household':1, 'Frozen Foods':0, 'Dairy':0,
                         'Baking Goods':0, 'Canned':0, 'Health and Hygiene':1, 'Meat':0, 'Soft Drinks':0,
                         'Breads':0, 'Hard Drinks':0, 'Others':2, 'Starchy Foods':0, 'Breakfast':0,'Seafood':0}},inplace =True)

df['Item_Type'].value_counts()

"""**Outlet_Identifier**"""

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier':{'OUT027':0,'OUT013':1,'OUT035':2,'OUT046':3,
                                 'OUT049':4,'OUT045':5,'OUT018':6,'OUT017':7,
                                 'OUT010':8,'OUT019':9}},inplace= True)

df[['Outlet_Identifier']].value_counts()

"""**Outlet_Size**"""

df[['Outlet_Size']].value_counts()

df.replace({'Outlet_Size':{'Medium':1,'Small':0,'High':2}},inplace= True)

df[['Outlet_Size']].value_counts()

"""**Outlet_Location_Type**"""

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type':{'Tier 2':1,'Tier 1':0,'Tier 3':2}},inplace= True)

df[['Outlet_Location_Type']].value_counts()

"""**Outlet_Type**"""

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type':{'Grocery Store':0,'Supermarket Type1':1,'Supermarket Type2':2,'Supermarket Type3':3}},inplace= True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

df.shape

"""## **Define Target Variable (y) and Feature Variable (X)**"""

y = df['Item_Outlet_Sales']

y.shape

y

"""####**Use .drop function to define (X)**"""

X = df.drop(['Item_Identifier','Item_Outlet_Sales'],axis =1)

X.shape

X

"""####**Standard Scaling Feature Variable(X)**"""

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()

X_scaled = df[['Item_Weight', 'Item_Visibility', 'Item_MRP','Outlet_Establishment_Year']]

X_scaled = ss.fit_transform(X_scaled)

X_scaled

X[['Item_Weight', 'Item_Visibility', 'Item_MRP','Outlet_Establishment_Year']] = pd.DataFrame(X_scaled,columns = [['Item_Weight', 'Item_Visibility', 'Item_MRP','Outlet_Establishment_Year']])

X

"""## **Train Test Split**"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X, y, train_size= 0.9, random_state =2529 )

X_train.shape ,X_test.shape ,Y_train.shape ,Y_test.shape

"""## **Modeling (Train Model)**

####**Linear Regressoin (Model_1)**
"""

from sklearn.linear_model import LinearRegression
Model_1 = LinearRegression()

Model_1.fit(X_train,Y_train)

Model_1.intercept_

Model_1.coef_

Y_pred_1 = Model_1.predict(X_test)

from sklearn.metrics import r2_score
r2_score(Y_test,Y_pred_1)

"""####**Random Forest Regressor (Model_2)**"""

from sklearn.ensemble import RandomForestRegressor
Model_2 = RandomForestRegressor(random_state=2529)

Model_2.fit(X_train,Y_train)

Y_pred_2 = Model_2.predict(X_test)

from sklearn.metrics import r2_score
r2_score(Y_test,Y_pred_2)

"""####**XGBRFRegressor (Model 3)**"""

from xgboost import XGBRFRegressor
Model_3 = XGBRFRegressor(random_state =2529)

Model_3.fit(X_train,Y_train)

Y_pred_3 = Model_3.predict(X_test)

from sklearn.metrics import r2_score
r2_score(Y_test,Y_pred_3)

"""####Note: Our Model_3 (XGBRFRegressor) have maximum r2_score (0.5980792779523648).
####So it will be our best Predictive Model

##**Best Model Training (XGBRFRegressor)**
"""

from xgboost import XGBRFRegressor
Model = XGBRFRegressor(random_state =2529)

Model.fit(X_train,Y_train)

"""## **Model Prediction**"""

Y_pred = Model.predict(X_test)

Y_pred.shape

Y_pred

"""## **Model Evaluation**"""

from sklearn.metrics import mean_absolute_percentage_error,mean_squared_error,mean_absolute_error,r2_score

mean_absolute_percentage_error(Y_test,Y_pred)

mean_squared_error(Y_test,Y_pred)

mean_absolute_error(Y_test,Y_pred)

r2_score(Y_test,Y_pred)

"""## **Get Visualization of Actual Vs Predicted Results**"""

import matplotlib.pyplot as plt
plt.scatter(Y_test,Y_pred)
plt.title('Actual Sales Vs Predicted Sales')
plt.xlabel("Actual Sales")
plt.ylabel("Predicted Sales")
plt.show()

"""## **Explaination**

We got our Big Sales dataset from www.github/YBI Foundation.Our dataset have countinous variable datapoints.So we have create diffrent Regression Model like Linear Regression, Random Forest Regression,XGBRF Regression to find out best Model based on maximum r2_score.Then we found out XGBRFRegressor Model have maximum r2_score.So we will go ahead with XGBRFRegressor Model and it would be best Predictive Model for our dataset.we Predict and Evalueate our final Model. Then Get Visualization of Actual Vs Predicted Results.
"""